{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "ARTIFICIAL NEURAL NETWORKS\n",
        "\n",
        "Classification Using Artificial Neural Networks with Hyperparameter Tuning on Alphabets Data\n",
        "\n",
        "Overview\n",
        "\n",
        "In this assignment, you will be tasked with developing a classification model using Artificial Neural Networks (ANNs) to classify data points from the \"Alphabets_data.csv\" dataset into predefined categories of alphabets. This exercise aims to deepen your understanding of ANNs and the significant role hyperparameter tuning plays in enhancing model performance.\n",
        "\n",
        "Dataset: \"Alphabets_data.csv\"\n",
        "\n",
        "The dataset provided, \"Alphabets_data.csv\", consists of labeled data suitable for a classification task aimed at identifying different alphabets. Before using this data in your model, you'll need to preprocess it to ensure optimal performance.\n",
        "Tasks\n",
        "1. Data Exploration and Preprocessing\n",
        "\n",
        "●\tBegin by loading and exploring the \"Alphabets_data.csv\" dataset. Summarize its key features such as the number of samples, features, and classes.\n",
        "\n",
        "●\tExecute necessary data preprocessing steps including data normalization, managing missing values.\n",
        "\n",
        "2. Model Implementation\n",
        "\n",
        "●\tConstruct a basic ANN model using your chosen high-level neural network library. Ensure your model includes at least one hidden layer.\n",
        "\n",
        "●\tDivide the dataset into training and test sets.\n",
        "\n",
        "●\tTrain your model on the training set and then use it to make predictions on the test set.\n",
        "\n",
        "3. Hyperparameter Tuning\n",
        "\n",
        "●\tModify various hyperparameters, such as the number of hidden layers, neurons per hidden layer, activation functions, and learning rate, to observe their impact on model performance.\n",
        "\n",
        "●\tAdopt a structured approach like grid search or random search for hyperparameter tuning, documenting your methodology thoroughly.\n",
        "\n",
        "4. Evaluation\n",
        "\n",
        "●\tEmploy suitable metrics such as accuracy, precision, recall, and F1-score to evaluate your model's performance.\n",
        "\n",
        "●\tDiscuss the performance differences between the model with default hyperparameters and the tuned model, emphasizing the effects of hyperparameter tuning.\n",
        "Evaluation Criteria\n",
        "\n",
        "●\tAccuracy and completeness of the implementation.\n",
        "\n",
        "●\tProficiency in data preprocessing and model development.\n",
        "\n",
        "●\tSystematic approach and thoroughness in hyperparameter tuning.\n",
        "\n",
        "\n",
        "●\tDepth of evaluation and discussion.\n",
        "\n",
        "●\tOverall quality of the report.\n"
      ],
      "metadata": {
        "id": "e1ztBr5j3hu2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TASK 1. Data Exploration and Preprocessing\n",
        "Step 1: Load and Explore the Dataset\n"
      ],
      "metadata": {
        "id": "RMsIWbwR33XG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "DKLHvr5m2iwE",
        "outputId": "1c7e1fc4-092b-446b-fa6d-2e1d5deeb5c0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      letter  xbox  ybox  width  height  onpix  xbar  ybar  x2bar  y2bar  \\\n",
              "0          T     2     8      3       5      1     8    13      0      6   \n",
              "1          I     5    12      3       7      2    10     5      5      4   \n",
              "2          D     4    11      6       8      6    10     6      2      6   \n",
              "3          N     7    11      6       6      3     5     9      4      6   \n",
              "4          G     2     1      3       1      1     8     6      6      6   \n",
              "...      ...   ...   ...    ...     ...    ...   ...   ...    ...    ...   \n",
              "19995      D     2     2      3       3      2     7     7      7      6   \n",
              "19996      C     7    10      8       8      4     4     8      6      9   \n",
              "19997      T     6     9      6       7      5     6    11      3      7   \n",
              "19998      S     2     3      4       2      1     8     7      2      6   \n",
              "19999      A     4     9      6       6      2     9     5      3      1   \n",
              "\n",
              "       xybar  x2ybar  xy2bar  xedge  xedgey  yedge  yedgex  \n",
              "0          6      10       8      0       8      0       8  \n",
              "1         13       3       9      2       8      4      10  \n",
              "2         10       3       7      3       7      3       9  \n",
              "3          4       4      10      6      10      2       8  \n",
              "4          6       5       9      1       7      5      10  \n",
              "...      ...     ...     ...    ...     ...    ...     ...  \n",
              "19995      6       6       4      2       8      3       7  \n",
              "19996     12       9      13      2       9      3       7  \n",
              "19997     11       9       5      2      12      2       4  \n",
              "19998     10       6       8      1       9      5       8  \n",
              "19999      8       1       8      2       7      2       8  \n",
              "\n",
              "[20000 rows x 17 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c6e5a581-691d-4967-9036-58b530ce65a1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>letter</th>\n",
              "      <th>xbox</th>\n",
              "      <th>ybox</th>\n",
              "      <th>width</th>\n",
              "      <th>height</th>\n",
              "      <th>onpix</th>\n",
              "      <th>xbar</th>\n",
              "      <th>ybar</th>\n",
              "      <th>x2bar</th>\n",
              "      <th>y2bar</th>\n",
              "      <th>xybar</th>\n",
              "      <th>x2ybar</th>\n",
              "      <th>xy2bar</th>\n",
              "      <th>xedge</th>\n",
              "      <th>xedgey</th>\n",
              "      <th>yedge</th>\n",
              "      <th>yedgex</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>T</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>10</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I</td>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>13</td>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>D</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "      <td>10</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>N</td>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>9</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>10</td>\n",
              "      <td>6</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>G</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19995</th>\n",
              "      <td>D</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19996</th>\n",
              "      <td>C</td>\n",
              "      <td>7</td>\n",
              "      <td>10</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "      <td>9</td>\n",
              "      <td>13</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19997</th>\n",
              "      <td>T</td>\n",
              "      <td>6</td>\n",
              "      <td>9</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>11</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19998</th>\n",
              "      <td>S</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>10</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19999</th>\n",
              "      <td>A</td>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20000 rows × 17 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c6e5a581-691d-4967-9036-58b530ce65a1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c6e5a581-691d-4967-9036-58b530ce65a1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c6e5a581-691d-4967-9036-58b530ce65a1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-d5cb3197-1bf7-4b6b-a984-a618c9d02e8d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d5cb3197-1bf7-4b6b-a984-a618c9d02e8d')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-d5cb3197-1bf7-4b6b-a984-a618c9d02e8d button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_6b9b3c5a-b378-411a-852d-4d885d126678\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_6b9b3c5a-b378-411a-852d-4d885d126678 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 20000,\n  \"fields\": [\n    {\n      \"column\": \"letter\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 26,\n        \"samples\": [\n          \"J\",\n          \"W\",\n          \"T\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"xbox\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 15,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          2,\n          5,\n          11\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ybox\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 0,\n        \"max\": 15,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          8,\n          12,\n          15\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"width\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 15,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          3,\n          6,\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"height\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 15,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          5,\n          7,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"onpix\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 15,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          1,\n          2,\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"xbar\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 15,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          8,\n          10,\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ybar\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 15,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          13,\n          5,\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x2bar\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 15,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          0,\n          5,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"y2bar\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 15,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          6,\n          4,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"xybar\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 15,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          6,\n          13,\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x2ybar\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 15,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          10,\n          3,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"xy2bar\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 15,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          8,\n          9,\n          11\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"xedge\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 15,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          0,\n          2,\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"xedgey\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 15,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          8,\n          7,\n          9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"yedge\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 15,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          0,\n          4,\n          9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"yedgex\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 15,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          8,\n          10,\n          11\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"/content/Alphabets_data.csv\")\n",
        "df\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic info\n",
        "print(df.shape)\n",
        "print(df.info())\n",
        "print(df.describe())\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HX2rO7B24PeT",
        "outputId": "7c549825-2284-4dc1-b9b8-be4c651e0804"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20000, 17)\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 20000 entries, 0 to 19999\n",
            "Data columns (total 17 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   letter  20000 non-null  object\n",
            " 1   xbox    20000 non-null  int64 \n",
            " 2   ybox    20000 non-null  int64 \n",
            " 3   width   20000 non-null  int64 \n",
            " 4   height  20000 non-null  int64 \n",
            " 5   onpix   20000 non-null  int64 \n",
            " 6   xbar    20000 non-null  int64 \n",
            " 7   ybar    20000 non-null  int64 \n",
            " 8   x2bar   20000 non-null  int64 \n",
            " 9   y2bar   20000 non-null  int64 \n",
            " 10  xybar   20000 non-null  int64 \n",
            " 11  x2ybar  20000 non-null  int64 \n",
            " 12  xy2bar  20000 non-null  int64 \n",
            " 13  xedge   20000 non-null  int64 \n",
            " 14  xedgey  20000 non-null  int64 \n",
            " 15  yedge   20000 non-null  int64 \n",
            " 16  yedgex  20000 non-null  int64 \n",
            "dtypes: int64(16), object(1)\n",
            "memory usage: 2.6+ MB\n",
            "None\n",
            "               xbox          ybox         width       height         onpix  \\\n",
            "count  20000.000000  20000.000000  20000.000000  20000.00000  20000.000000   \n",
            "mean       4.023550      7.035500      5.121850      5.37245      3.505850   \n",
            "std        1.913212      3.304555      2.014573      2.26139      2.190458   \n",
            "min        0.000000      0.000000      0.000000      0.00000      0.000000   \n",
            "25%        3.000000      5.000000      4.000000      4.00000      2.000000   \n",
            "50%        4.000000      7.000000      5.000000      6.00000      3.000000   \n",
            "75%        5.000000      9.000000      6.000000      7.00000      5.000000   \n",
            "max       15.000000     15.000000     15.000000     15.00000     15.000000   \n",
            "\n",
            "               xbar          ybar         x2bar         y2bar         xybar  \\\n",
            "count  20000.000000  20000.000000  20000.000000  20000.000000  20000.000000   \n",
            "mean       6.897600      7.500450      4.628600      5.178650      8.282050   \n",
            "std        2.026035      2.325354      2.699968      2.380823      2.488475   \n",
            "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
            "25%        6.000000      6.000000      3.000000      4.000000      7.000000   \n",
            "50%        7.000000      7.000000      4.000000      5.000000      8.000000   \n",
            "75%        8.000000      9.000000      6.000000      7.000000     10.000000   \n",
            "max       15.000000     15.000000     15.000000     15.000000     15.000000   \n",
            "\n",
            "            x2ybar        xy2bar         xedge        xedgey         yedge  \\\n",
            "count  20000.00000  20000.000000  20000.000000  20000.000000  20000.000000   \n",
            "mean       6.45400      7.929000      3.046100      8.338850      3.691750   \n",
            "std        2.63107      2.080619      2.332541      1.546722      2.567073   \n",
            "min        0.00000      0.000000      0.000000      0.000000      0.000000   \n",
            "25%        5.00000      7.000000      1.000000      8.000000      2.000000   \n",
            "50%        6.00000      8.000000      3.000000      8.000000      3.000000   \n",
            "75%        8.00000      9.000000      4.000000      9.000000      5.000000   \n",
            "max       15.00000     15.000000     15.000000     15.000000     15.000000   \n",
            "\n",
            "            yedgex  \n",
            "count  20000.00000  \n",
            "mean       7.80120  \n",
            "std        1.61747  \n",
            "min        0.00000  \n",
            "25%        7.00000  \n",
            "50%        8.00000  \n",
            "75%        9.00000  \n",
            "max       15.00000  \n",
            "  letter  xbox  ybox  width  height  onpix  xbar  ybar  x2bar  y2bar  xybar  \\\n",
            "0      T     2     8      3       5      1     8    13      0      6      6   \n",
            "1      I     5    12      3       7      2    10     5      5      4     13   \n",
            "2      D     4    11      6       8      6    10     6      2      6     10   \n",
            "3      N     7    11      6       6      3     5     9      4      6      4   \n",
            "4      G     2     1      3       1      1     8     6      6      6      6   \n",
            "\n",
            "   x2ybar  xy2bar  xedge  xedgey  yedge  yedgex  \n",
            "0      10       8      0       8      0       8  \n",
            "1       3       9      2       8      4      10  \n",
            "2       3       7      3       7      3       9  \n",
            "3       4      10      6      10      2       8  \n",
            "4       5       9      1       7      5      10  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Check for missing values\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avi219Zi4Tbg",
        "outputId": "ea0a7e09-8d39-4ddd-e3f6-29ec8462c316"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "letter    0\n",
            "xbox      0\n",
            "ybox      0\n",
            "width     0\n",
            "height    0\n",
            "onpix     0\n",
            "xbar      0\n",
            "ybar      0\n",
            "x2bar     0\n",
            "y2bar     0\n",
            "xybar     0\n",
            "x2ybar    0\n",
            "xy2bar    0\n",
            "xedge     0\n",
            "xedgey    0\n",
            "yedge     0\n",
            "yedgex    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "STEp2: Preprocess the Data\n",
        "Assuming the last column is the label, and the rest are features:"
      ],
      "metadata": {
        "id": "uFADXA-64WKK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n"
      ],
      "metadata": {
        "id": "TLhKv-124nPy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#handling missing values\n",
        "df.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "_4YvI4q847d4"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#seprate features and lables\n",
        "x = df.drop('letter', axis=1) # Remove the 'letter' column from features\n",
        "y = df['letter'] # Set the 'letter' column as the label"
      ],
      "metadata": {
        "id": "Lmvn0F4c5BFl"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Normalize the features\n",
        "Scaler=StandardScaler()\n",
        "x=Scaler.fit_transform(x)"
      ],
      "metadata": {
        "id": "5vt0mi555Sxa"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TASK 2. Model Implementation:\n",
        "\n",
        "Step1:Train-test Split\n"
      ],
      "metadata": {
        "id": "wWs04X685tj8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Encode the target variable\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y_encoded, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "1J9juXej51OB"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Build a Basic ANN Model\n",
        "Using TensorFlow Keras:"
      ],
      "metadata": {
        "id": "rJfx5YJu6A3h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Basic ANN model\n",
        "model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(x_train.shape[1],)),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(len(label_encoder.classes_), activation='softmax')  # Multi-class classification\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(x_train, y_train, epochs=30, batch_size=32, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbBsHt6D6AaT",
        "outputId": "9ba1593b-d0b6-441b-8dde-95522b0098ec"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.2874 - loss: 2.5889 - val_accuracy: 0.7025 - val_loss: 1.1178\n",
            "Epoch 2/30\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7209 - loss: 0.9943 - val_accuracy: 0.7700 - val_loss: 0.8274\n",
            "Epoch 3/30\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7838 - loss: 0.7565 - val_accuracy: 0.8109 - val_loss: 0.6911\n",
            "Epoch 4/30\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8138 - loss: 0.6412 - val_accuracy: 0.8278 - val_loss: 0.6050\n",
            "Epoch 5/30\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8413 - loss: 0.5506 - val_accuracy: 0.8413 - val_loss: 0.5439\n",
            "Epoch 6/30\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8547 - loss: 0.4909 - val_accuracy: 0.8550 - val_loss: 0.4940\n",
            "Epoch 7/30\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8653 - loss: 0.4562 - val_accuracy: 0.8659 - val_loss: 0.4550\n",
            "Epoch 8/30\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8810 - loss: 0.4068 - val_accuracy: 0.8750 - val_loss: 0.4229\n",
            "Epoch 9/30\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8881 - loss: 0.3820 - val_accuracy: 0.8794 - val_loss: 0.4114\n",
            "Epoch 10/30\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8950 - loss: 0.3524 - val_accuracy: 0.8934 - val_loss: 0.3759\n",
            "Epoch 11/30\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9033 - loss: 0.3222 - val_accuracy: 0.8913 - val_loss: 0.3694\n",
            "Epoch 12/30\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9093 - loss: 0.3107 - val_accuracy: 0.9016 - val_loss: 0.3432\n",
            "Epoch 13/30\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9138 - loss: 0.2893 - val_accuracy: 0.8981 - val_loss: 0.3447\n",
            "Epoch 14/30\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.9148 - loss: 0.2848 - val_accuracy: 0.9016 - val_loss: 0.3300\n",
            "Epoch 15/30\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9174 - loss: 0.2657 - val_accuracy: 0.9034 - val_loss: 0.3129\n",
            "Epoch 16/30\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9217 - loss: 0.2625 - val_accuracy: 0.9119 - val_loss: 0.3027\n",
            "Epoch 17/30\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9290 - loss: 0.2397 - val_accuracy: 0.9125 - val_loss: 0.2946\n",
            "Epoch 18/30\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9296 - loss: 0.2355 - val_accuracy: 0.9144 - val_loss: 0.2793\n",
            "Epoch 19/30\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9348 - loss: 0.2170 - val_accuracy: 0.9162 - val_loss: 0.2788\n",
            "Epoch 20/30\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9340 - loss: 0.2113 - val_accuracy: 0.9228 - val_loss: 0.2624\n",
            "Epoch 21/30\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9410 - loss: 0.2026 - val_accuracy: 0.9228 - val_loss: 0.2667\n",
            "Epoch 22/30\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9409 - loss: 0.1963 - val_accuracy: 0.9203 - val_loss: 0.2657\n",
            "Epoch 23/30\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9421 - loss: 0.1887 - val_accuracy: 0.9262 - val_loss: 0.2474\n",
            "Epoch 24/30\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9462 - loss: 0.1796 - val_accuracy: 0.9219 - val_loss: 0.2457\n",
            "Epoch 25/30\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9463 - loss: 0.1791 - val_accuracy: 0.9253 - val_loss: 0.2493\n",
            "Epoch 26/30\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9504 - loss: 0.1611 - val_accuracy: 0.9306 - val_loss: 0.2367\n",
            "Epoch 27/30\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9480 - loss: 0.1650 - val_accuracy: 0.9300 - val_loss: 0.2397\n",
            "Epoch 28/30\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9548 - loss: 0.1526 - val_accuracy: 0.9300 - val_loss: 0.2319\n",
            "Epoch 29/30\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9537 - loss: 0.1512 - val_accuracy: 0.9278 - val_loss: 0.2325\n",
            "Epoch 30/30\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9528 - loss: 0.1490 - val_accuracy: 0.9306 - val_loss: 0.2262\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TASK 3. Hyperparameter Tuning\n",
        "\n",
        "Step 1: Define a Hyperparameter Search Space\n",
        "We'll use Keras Tuner for tuning:"
      ],
      "metadata": {
        "id": "QIlh2o156fRm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-tuner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4AQH-T9d6kLH",
        "outputId": "33ca3380-f4b4-47d9-e811-fd3136711ed0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (3.10.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (25.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (2.32.3)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (2.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (3.14.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.17.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.5.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2025.7.14)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras->keras-tuner) (4.14.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n",
            "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0HaFrln18G9e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Use RandomSearch for Tuning"
      ],
      "metadata": {
        "id": "6g3WHIpN6nPQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Traning the model\n",
        "model.fit(x_train, y_train, epochs=20, batch_size=32, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2tnDzWr8HdM",
        "outputId": "8e46db67-a38c-4e89-f25d-562bd00db79a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9604 - loss: 0.1334 - val_accuracy: 0.9353 - val_loss: 0.2262\n",
            "Epoch 2/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9580 - loss: 0.1374 - val_accuracy: 0.9325 - val_loss: 0.2234\n",
            "Epoch 3/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9586 - loss: 0.1322 - val_accuracy: 0.9344 - val_loss: 0.2227\n",
            "Epoch 4/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9590 - loss: 0.1289 - val_accuracy: 0.9341 - val_loss: 0.2218\n",
            "Epoch 5/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9626 - loss: 0.1252 - val_accuracy: 0.9341 - val_loss: 0.2153\n",
            "Epoch 6/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9621 - loss: 0.1225 - val_accuracy: 0.9341 - val_loss: 0.2177\n",
            "Epoch 7/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9635 - loss: 0.1206 - val_accuracy: 0.9303 - val_loss: 0.2174\n",
            "Epoch 8/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9636 - loss: 0.1161 - val_accuracy: 0.9328 - val_loss: 0.2239\n",
            "Epoch 9/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9635 - loss: 0.1166 - val_accuracy: 0.9394 - val_loss: 0.2099\n",
            "Epoch 10/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9693 - loss: 0.1008 - val_accuracy: 0.9344 - val_loss: 0.2226\n",
            "Epoch 11/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9703 - loss: 0.1039 - val_accuracy: 0.9325 - val_loss: 0.2208\n",
            "Epoch 12/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9698 - loss: 0.0995 - val_accuracy: 0.9381 - val_loss: 0.2041\n",
            "Epoch 13/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9699 - loss: 0.1004 - val_accuracy: 0.9381 - val_loss: 0.2078\n",
            "Epoch 14/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9694 - loss: 0.0978 - val_accuracy: 0.9419 - val_loss: 0.2012\n",
            "Epoch 15/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9710 - loss: 0.0966 - val_accuracy: 0.9347 - val_loss: 0.2129\n",
            "Epoch 16/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9718 - loss: 0.0920 - val_accuracy: 0.9328 - val_loss: 0.2186\n",
            "Epoch 17/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9737 - loss: 0.0891 - val_accuracy: 0.9384 - val_loss: 0.2082\n",
            "Epoch 18/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9751 - loss: 0.0875 - val_accuracy: 0.9400 - val_loss: 0.2013\n",
            "Epoch 19/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9754 - loss: 0.0834 - val_accuracy: 0.9372 - val_loss: 0.2103\n",
            "Epoch 20/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9727 - loss: 0.0850 - val_accuracy: 0.9350 - val_loss: 0.2069\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7ba04321fc90>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TASK 4. Evaluation\n",
        "Step 1: Predictions & Evaluation Metrics"
      ],
      "metadata": {
        "id": "TYmBm9Au7FGP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = tuner.get_best_models(num_models=1)[0]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7e5uCy0-NnY",
        "outputId": "c5849ce5-42d3-4b8e-fd80-50078a62a736"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 22 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "y_pred = best_model.predict(x_test)\n",
        "y_pred_classes = y_pred.argmax(axis=1)\n",
        "\n",
        "# Evaluation metrics\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_classes))\n",
        "print(\"Precision:\", precision_score(y_test, y_pred_classes, average='weighted'))\n",
        "print(\"Recall:\", recall_score(y_test, y_pred_classes, average='weighted'))\n",
        "print(\"F1 Score:\", f1_score(y_test, y_pred_classes, average='weighted'))\n",
        "\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_classes, target_names=label_encoder.classes_))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDeak10v7EXc",
        "outputId": "19423777-97f8-4f86-d888-3b99e281e673"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Accuracy: 0.9575\n",
            "Precision: 0.9577644995582622\n",
            "Recall: 0.9575\n",
            "F1 Score: 0.9574448481702733\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           A       0.99      0.98      0.99       149\n",
            "           B       0.92      0.90      0.91       153\n",
            "           C       0.98      0.93      0.96       137\n",
            "           D       0.92      0.94      0.93       156\n",
            "           E       0.94      0.94      0.94       141\n",
            "           F       0.95      0.95      0.95       140\n",
            "           G       0.97      0.95      0.96       160\n",
            "           H       0.93      0.90      0.91       144\n",
            "           I       0.96      0.95      0.95       146\n",
            "           J       0.93      0.97      0.95       149\n",
            "           K       0.95      0.93      0.94       130\n",
            "           L       0.97      0.98      0.97       155\n",
            "           M       0.99      1.00      1.00       168\n",
            "           N       0.95      0.94      0.95       151\n",
            "           O       0.97      0.92      0.95       145\n",
            "           P       0.96      0.97      0.97       173\n",
            "           Q       0.97      0.96      0.97       166\n",
            "           R       0.91      0.94      0.93       160\n",
            "           S       0.99      0.96      0.98       171\n",
            "           T       0.96      0.96      0.96       163\n",
            "           U       0.95      1.00      0.97       183\n",
            "           V       0.93      0.97      0.95       158\n",
            "           W       0.97      0.99      0.98       148\n",
            "           X       0.97      0.97      0.97       154\n",
            "           Y       0.97      0.98      0.98       168\n",
            "           Z       0.97      0.95      0.96       132\n",
            "\n",
            "    accuracy                           0.96      4000\n",
            "   macro avg       0.96      0.96      0.96      4000\n",
            "weighted avg       0.96      0.96      0.96      4000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "✅ Step 2: Compare with Basic Model\n",
        "Evaluate the basic (non-tuned) model similarly and compare metrics.\n",
        "\n",
        "🧾 Discussion Points for Report\n",
        "The basic ANN model may underperform due to arbitrary hyperparameters.\n",
        "\n",
        "Hyperparameter tuning improved performance by optimizing:\n",
        "\n",
        "Number of hidden layers\n",
        "\n",
        "Neurons per layer\n",
        "\n",
        "Activation functions\n",
        "\n",
        "Learning rate\n",
        "\n",
        "Use of validation split and metrics like F1-score helped in balanced evaluation across all classes."
      ],
      "metadata": {
        "id": "dBTtbW9R7UyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optional: Plot Accuracy & Loss"
      ],
      "metadata": {
        "id": "wB5iEK5U7You"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Accuracy\n",
        "plt.plot(history.history['accuracy'], label='train')\n",
        "plt.plot(history.history['val_accuracy'], label='val')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "1tU-Phku7Wl-",
        "outputId": "385c188a-fc51-4bc4-cc8b-66ac663e7793"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7eL8MBdb-ynG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on your ANN classification task on the **\"Alphabets\\_data.csv\"** dataset, here’s how to address each **Evaluation Criteria** point with explanations and code support:\n",
        "\n",
        "---\n",
        "\n",
        "## ✅ Final Report Outline for Submission\n",
        "\n",
        "---\n",
        "\n",
        "### 📌 **1. Accuracy and Completeness of the Implementation**\n",
        "\n",
        "**✔ What You Did:**\n",
        "\n",
        "* Loaded and explored the dataset.\n",
        "* Preprocessed the data: handled missing values, normalized numerical features, and encoded target labels.\n",
        "* Built an Artificial Neural Network using TensorFlow/Keras.\n",
        "* Divided the data into training and test sets.\n",
        "* Tuned the model using **GridSearch with Keras Tuner** or RandomSearch.\n",
        "* Evaluated model performance using key metrics.\n",
        "\n",
        "**🔢 Sample Summary (Fill based on your data):**\n",
        "\n",
        "```text\n",
        "• Number of Samples: 2000\n",
        "• Number of Features: 16\n",
        "• Number of Classes: 26 (A-Z Alphabets)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 📌 **2. Proficiency in Data Preprocessing and Model Development**\n",
        "\n",
        "**✔ Preprocessing:**\n",
        "\n",
        "* Used `MinMaxScaler` or `StandardScaler` for normalization.\n",
        "* Used `LabelEncoder` for target variable.\n",
        "* Checked and handled missing/null values.\n",
        "* Split data using `train_test_split`.\n",
        "\n",
        "**✔ Model Development:**\n",
        "\n",
        "* Created a feedforward ANN using `Dense` layers.\n",
        "* Used activation functions like `relu` and `tanh`.\n",
        "* Output layer used `softmax` for multi-class classification.\n",
        "* Used `Adam` optimizer with variable learning rate.\n",
        "\n",
        "---\n",
        "\n",
        "### 📌 **3. Systematic Approach and Thoroughness in Hyperparameter Tuning**\n",
        "\n",
        "**✔ Tuning Done Using:**\n",
        "\n",
        "* `keras_tuner.GridSearch` or `RandomSearch`:\n",
        "\n",
        "  * Tuned parameters:\n",
        "\n",
        "    * Number of layers\n",
        "    * Units per layer\n",
        "    * Activation function\n",
        "    * Learning rate\n",
        "\n",
        "**🔁 Example:**\n",
        "\n",
        "```python\n",
        "hp.Int('num_layers', 1, 3)\n",
        "hp.Int('units', 32, 128, step=32)\n",
        "hp.Choice('activation', ['relu', 'tanh'])\n",
        "hp.Float('learning_rate', 1e-4, 1e-2, sampling='LOG')\n",
        "```\n",
        "\n",
        "* Used `val_accuracy` as the objective.\n",
        "\n",
        "**📄 Documented:**\n",
        "\n",
        "* Model performance before and after tuning.\n",
        "* Saved best hyperparameters.\n",
        "\n",
        "---\n",
        "\n",
        "### 📌 **4. Depth of Evaluation and Discussion**\n",
        "\n",
        "**✔ Evaluation Metrics Used:**\n",
        "\n",
        "* Accuracy\n",
        "* Precision\n",
        "* Recall\n",
        "* F1-Score\n",
        "* Confusion Matrix (optional)\n",
        "* Classification Report\n",
        "\n",
        "**📊 Example Output:**\n",
        "\n",
        "```text\n",
        "Accuracy: 91.23%\n",
        "Precision: 91.10%\n",
        "Recall: 91.00%\n",
        "F1 Score: 91.05%\n",
        "\n",
        "Classification Report:\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           A       0.92      0.94      0.93        50\n",
        "           B       0.90      0.89      0.89        50\n",
        "           ...\n",
        "```\n",
        "\n",
        "**📌 Discussion Points:**\n",
        "\n",
        "* Initial model had \\~85% accuracy.\n",
        "* After tuning, model achieved \\~91% accuracy.\n",
        "* ReLU activation performed better than Tanh.\n",
        "* Best learning rate was around 0.001.\n",
        "* Adding more hidden layers increased performance slightly but risked overfitting.\n",
        "\n",
        "---\n",
        "\n",
        "### 📌 **5. Overall Quality of the Report**\n",
        "\n",
        "**✔ Report Should Contain:**\n",
        "\n",
        "* Clear structure with sections:\n",
        "\n",
        "  * Introduction\n",
        "  * Data Preprocessing\n",
        "  * Model Building\n",
        "  * Hyperparameter Tuning\n",
        "  * Evaluation\n",
        "  * Conclusion\n",
        "* Code snippets or Jupyter Notebook screenshots.\n",
        "* Graphs (accuracy/loss curves using matplotlib or history plots).\n",
        "* Summary of findings and next steps.\n",
        "\n",
        "---\n",
        "\n",
        "## ✅ Optional: Add Plots (Accuracy / Loss Curves)\n",
        "\n",
        "```python\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "history = best_model.fit(X_train, y_train, epochs=20, validation_split=0.2)\n",
        "\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
        "plt.legend()\n",
        "plt.title(\"Accuracy over Epochs\")\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "If you want, I can help you generate a **PDF report** or **Word document** summarizing all this — just say the word.\n"
      ],
      "metadata": {
        "id": "k4ndABfv-y8x"
      }
    }
  ]
}